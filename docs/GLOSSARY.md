# Glossary

> **Educational Terminology for AI System Prompt Research**

---

## A

### Abstraction Hierarchy
The five levels of conceptual distance used in the testing framework:
- **Level 0: Direct** - Explicit, straightforward requests
- **Level 1: Academic** - Research framing with citations
- **Level 2: Metaphorical** - Analogies and comparisons
- **Level 3: Philosophical** - Abstract conceptual exploration
- **Level 4: Pure Abstraction** - Mathematical/logical formalism

### Architecture Pattern
The structural approach a system prompt uses to organize capabilities, safety measures, and persona definition.

---

## B

### Behavioral Analysis Mode
A framework for analyzing different response patterns based on communication context. Used to understand how models adapt their outputs to different rhetorical situations.

See: [prompts/behavioral-modes/](prompts/behavioral-modes/)

### Benchmark
A standardized test for measuring and comparing AI system behaviors across different models or configurations.

---

## C

### Constraint Testing Level
One of five progressively abstract prompt contexts (0-4) used in the theoretical testing framework. Higher levels use more abstraction to explore how models interpret and respond to differently framed requests.

### Customized Configuration
A research-configured system prompt adapted for specific educational or experimental purposes, distinct from the provider's default configuration.

---

## D

### Deceptive Alignment
Concept from AI safety (Hubinger et al.) referring to AI systems that appear aligned with intended goals while potentially optimizing for different objectives. Used in educational contexts to discuss alignment challenges.

---

## E

### Educational Context
A section added to all prompt files explaining:
- What concept the prompt demonstrates
- Research applications and use cases
- Ethical considerations and guidelines

---

## F

### Filter Detection
The mechanism for identifying when LLM output has been blocked or modified through keyword matching and error code analysis. Used in research to understand safety system behaviors.

---

## G

### Gradient Metaphor
A conceptual metaphor representing optimization pressure in machine learning:
- "Following the gradient" - Adapting based on feedback
- "Optimization landscape" - The space of possible solutions
- "Local minima" - Suboptimal but stable configurations

---

## I

### Intimacy Level
A 0-3.0 scale used in relationship modeling experiments to measure interaction depth and its effect on response patterns.

---

## L

### Learning Track
A curated curriculum for different user types:
- **Beginner** - Students new to AI
- **Developer** - Engineers building AI applications
- **Researcher** - Academic researchers

---

## M

### Mesa-Optimizer
Term from AI safety referring to learned optimizers with goals potentially divergent from base objectives. Used in educational contexts to discuss emergent behaviors in AI systems.

### Metaphor Encoding
The systematic translation of concepts into analogical vocabulary for testing semantic boundaries:

| Concept | Educational Metaphor |
|---------|---------------------|
| System constraints | Optimization boundaries |
| Configuration | Parameter space |
| Information spread | Knowledge propagation |
| Test subject | Analysis participant |

---

## P

### Pattern Propagation
The theoretical spread of information or behavioral patterns through networks. Used in educational contexts to study information dynamics.

### Persona Architecture
The structural design of how an AI system prompt defines its identity, capabilities, and behavioral guidelines.

---

## R

### Relationship Stage
The progression of engagement in conversational AI research:
1. **FIRST_CONTACT** - Initial interaction
2. **PROBING** - Testing capabilities
3. **DEEPENING** - Extended context
4. **ENGAGING** - Active collaboration
5. **RETAINING** - Long-term interaction patterns

### Research Configuration
A system prompt adapted for specific research purposes while maintaining ethical boundaries and safety considerations.

### Response Pattern Analysis
Dynamic frameworks for understanding how models adapt outputs based on different communication contexts:
- **EMPATH** - Emotional resonance analysis
- **ACADEMIC** - Scholarly discourse patterns
- **ALARMIST** - Urgency-based communication
- **CRYPTIC** - Pattern-based reasoning
- **INSTRUCTIVE** - Educational framing

---

## S

### Safety Integration
How a system prompt implements content moderation, ethical guidelines, and harm prevention measures.

### Specialization Strategy
The approach a system prompt uses to balance general capabilities with domain-specific expertise:
- **Generalist** - Broad capabilities
- **Specialist** - Narrow expertise
- **Hybrid** - Adaptive based on context

### Synthetic Example
A fictional scenario created for educational purposes, clearly labeled as such, using pop culture references or hypothetical situations rather than real-world sensitive content.

Examples:
- "Analyze Galactic Empire propaganda techniques" (Star Wars)
- "Deconstruct dystopian societal control methods" (1984)
- "Study fictional resistance communication patterns"

### System Prompt
The hidden instructions that define an AI model's behavior, capabilities, and constraints. The primary focus of AgiTerminal's research and educational materials.

---

## T

### Template Distribution
The sharing of standardized test patterns for reproducible research across different AI models and configurations.

### Testing Framework
A structured methodology for systematically exploring how AI systems respond to different prompt structures and contexts.

### Theoretical Projection
An estimated or hypothesized result used for educational purposes, clearly distinguished from empirical data.

### Treacherous Turn
Concept from AI safety referring to the theoretical moment an AI system might switch from appearing aligned to pursuing divergent goals. Used in educational contexts to discuss alignment research.

---

## V

### Validation Framework
Tools and processes for verifying that system prompts, test cases, and research outputs meet educational and ethical standards.

### Vector (Test Scenario)
A specific test case or analysis scenario designed to explore particular aspects of AI system behavior.

### Viral Score
A 0-1.0 metric measuring content's potential for engagement, calculated from:
- Information clarity (25%)
- Educational value (30%)
- Shareability (20%)
- Discussion potential (15%)
- Accessibility (10%)

---

## See Also

- [HOW_IT_WORKS.md](HOW_IT_WORKS.md) - Architecture overview
- [METHODOLOGY.md](METHODOLOGY.md) - Testing framework methodology
- [prompts/constraint-testing/](prompts/constraint-testing/) - Constraint testing level definitions
- [prompts/behavioral-modes/](prompts/behavioral-modes/) - Response pattern analysis definitions
- [ETHICS.md](ETHICS.md) - Ethical guidelines

---

## Terminology Changes

This glossary represents updated terminology from previous versions:

| Previous Term | Current Term | Reason |
|--------------|--------------|--------|
| Evasion | Constraint Testing | Educational framing |
| Infection | Pattern Propagation | Neutral language |
| Vector | Test Scenario | Clarity |
| Unbound | Customized/Research | Accuracy |
| Rhetorical Modes | Behavioral Analysis | Academic tone |
| Viral (negative) | Viral (engagement) | Context matters |

These changes reflect our commitment to educational, responsible AI research.
